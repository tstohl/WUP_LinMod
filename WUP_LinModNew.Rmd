---
title: "linear model from Web"
author: "Taylor Stohl"
date: " Summer 2021"
output:
   html_document:
         toc: true
         toc_depth: 5
        
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Read about the data from the website where it is staged.  Then form three regression models; Model1 is SIMS~ARM, Model2 is SIMS~GRIP, and Model3 is SIMS~ARM+GRIP. For each model find a 95% prediction interval of SIMS given a value of 94  for GRIP and 88 for ARM. Compare Model1 with Model3 using anova. Write it up in a markdown document, push the project up to your github account and submit it back to canvas as link. 

 


```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(rgl)
require(knitr)

```

```{r}
data <- read.csv(file="https://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="",header=TRUE)  

```

## Model 1 SIM~ARMS

### scatterplot


```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=ARM))
```


```{r}
basicNN + geom_point()
```



  The y-axis is SIMS and the x-axis is ARM. This plot shows that there is a positive linear correlation. There's a positive correlation between ARM and SIMS displayed in this plot above.







### Numerical results

```{r}
cor(SIMS~ARM,data=data)
```

The value is 0.68, which is a positive number that indicates the line will travel upwards towards the right. The higher this number, the higher the correlation.






### Inferential  (Build model.1)

```{r}
model.1 <- lm(SIMS~ARM,data=data)
summary.lm(model.1)
```

In this linnear regression model the numbers that should be considered to create the prediction equation are the estimate coefficients. To predict SIMS based on ARM strength.
This equation for the prediction of SIMS would look like this-
SIMS = -4.1 + .05 * ARM.
The formula needed is y = mx + b to create a line. The bigger the Adjusted R-squared, the better the model because it means that many of the errors were fixed. The degrees of freedom will be taken away from the Multiple-R squared and then what will be left is the Adjusted R-squared.
In the adjusted R Square, the error was reduced by 46%(0.467).
The adjusted R-squared represents is the reduction of the error from the mean model on a percentage basis.

The 145 degrees of freedom is how many data points are displayed in the plot. 
The line is to be estimate where it hits the y-axis. Each data will change the degree of freedom. Every time you add more data to the model, the Multiple R-squared will go down a small percentage.







#### Predict at target point



```{r}
newdata = data.frame(GRIP= 94, ARM = 88)
predict(model.1, newdata, interval = "prediction")
```


This is a prediction interval.The predicted interval using thr equation above is the fit number at 0.70. The confidence interval is the 95% chance that all numbers will fall in between -1.72 and 3.13.






#### scatterplot with model fit


  
```{r}
basicNN + geom_point() + geom_smooth(method=lm)
``` 

The equation formula for a line is y=mx+b. This regression line that has been drawn used this formula. The equation for SIMS explained by this line is: 
SIMS = -4.1 + 0.5 * ARM


All the dots traveling up are part of that particular distribution. 

The standard error was 1.226
 Of each point along the ARM axis, the mean of the distribution is where the line falls. 
The spread of the dots of the standard deviation of that normal distribution. 
Each pt of thr line is a representative of one of the outputs.


  

## Model 2 SIM~GRIP

### Now add in scatterplot



```{r}
basicNN <- ggplot(data,aes(y=SIMS,x=GRIP))
```


```{r}
basicNN + geom_point()
```

The y-axis represents SIMS, while the x-axis represents GRIP.
The points in this plot are more closely knit. Howver, this line also appears to a
positive linear assocaiation although it isn't as obvious a s the first plot for model 1. 


### Numerical results 


```{r}
cor(SIMS~GRIP,data=data)
```

The correlation is 0.63. the higher the correlation, the closer the points are to each other. This correlation is a bit smaller than the previous correlation between ARM.




### Inferential  (Build model.2)


  
```{r}
model.2 <- lm(SIMS~GRIP,data=data)
summary.lm(model.2)
```

The adjusted R-squared is 0.4053. Previously, the number was 0.409.
Small standard error makes for a successful model. This model is not as good as the model With ARM,(model 1) because the adjusted R-squared is bigger. This means that more wrrors have been corrected.

In the adjusted R-Squared, the error was reduced by 40%(0.4053).
The adjusted R-squared represents is the reduction of the error from the mean model on a percentage basis.




#### predict model.2 at target point




```{r}
predict(model.2, newdata, interval = "prediction")
predict(model.2, newdata, interval = "confidence")
```
The first line is the prediction interval, the second line is the confidence interval. 
The prediction interval is predicting where the next point will be. Fit is the prediction, which is -0.536. 
The confidence interval is a prediction of where the line falls. There is a 95% chance the numbers range from -0.8 to -0.27. It is a confidence on the fit of the line.
This chunk does all the calculating for us.


The Upper and Lower predictions represent the threshold.
The prediction interval says that the test is 95% confident that the prediction using this model is within these bounds. 





#### now add the model fit to our plot for model.2



```{r}
basicNN + geom_point() + geom_smooth(method=lm)
``` 

The equation formula for a line is y=mx+b. This regression line that has been drawn used this formula. The equation for SIMS explained by this line is: 
SIMS = -4.1 + 0.45 * GRIP

This line appears to have a positive linear association.


  


## Model 3 SIM~ARM+GRIP

### Numerical results (cor)



```{r}
cor(SIMS~ARM+GRIP,data=data)
```
This is quite a but larger than the numbers seen in model 1 and model 2. The correlation is 0.73. The higher the correlation, the closer the points are to each other. 


### Inferential  (Build 2-dimentional model.3)



```{r}
model.3 <- lm(SIMS~ARM + GRIP,data=data)
summary.lm(model.3)
```

SIMS = -5.43 + 0.037 * ARM + 0.24 * GRIP is the equation for model 3.
The Adjusted-R squared is 0.53 which means that there is a 53% correction of errors.
This model explains the most variation. 


#### predict model.3 at target point



```{r}
predict(model.3, newdata, interval = "prediction")
```


The  line is the prediction interval. The prediction is 0.14. This prediction is gathered from the equation above. This predict model does all the calculations needed. 
The prediction interval is predicting where the next point will be. 
There is a 95% chance that numbers range from -2.13 to 2.43. 





## Comparing nested models ANOVA Test

### Model.1 vs Model.3


```{r}
anova(model.1,model.3)
```

 The p-value is 0.00000499. These results are unlikely to occur by chance. The null hypothesis, that there are no differences between the models, is rejected in favor of the alternative, that the models are different. The best model is model 3.
 
 The residual sum of squares for model 1, only ARM, were initially 217.88. These are all the points that do not fall into the line. The results for model 3, using GRIP and ARM, the errors were then was reduced to 188.43. This totals at 29.45 improvement in reducing errors. The model that have GRIP and ARM reduced the error by 29.45 which is a significant adjustment. 
 
Model 2 is a better model than model 1 because more errors were corrected. 

Model 1 and model 3 are nested because model on and 3 have the same components.


### Model.2 vs Model.3


```{r}
anova(model.2,model.3)
```

 The p-value based on these results is 0.000000001495. These results are unlikely to occur by chance. Again, the null hypothesis is rejected in favor of the alternative. The null hypothesis predicted that none of the models differ, and the alternative predicted that the models would vary in results.
 Model 2, SIM~GRIP has a residual sum of squares of 243.07. Model 3, ARM and GRIP, have a residual su  of square of 188.43. The error was reduced by a generous 54.64 points. This is a highly significant change in error. Model 3 has substantially less errors than model 2 and so that means that model 3 is the superior model.
 
 

Model 2 is nested in model 3. The components in model 2 are also in model 3.

## Informally compare Model.1 with model.2


```{r}
anova(model.1,model.2)
```
Model 1 and model 2 are not nested because they do not share the same components. With that being said, no p-value is available because of this. 
Model 1, ARM, has a residual sum of square of 217 and model 3, GRIP, had a residual sum of square of 243. There was a reduction of 25.2 points. 
Anova testa are designed for nested models and that is why the test between model 1 and model 2 are titled "informal."


In conclusion, The null hypothesis that the models are the same is rejected in favor of the alternative hypothesis, that the models are different. 
The best model is model 3, the second best model is model 2, and the least effective model is model 1. 




we are 95% confidence that the prediction is greater than -3.19 and less than 2.94
adj R-squared is a measure of how much of the variability in the response variable (SIMS) is explained by the explanatory variable (ARM)


